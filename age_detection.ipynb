{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d2d3326-4fb0-45da-8d22-405226ee34bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09be9438-b52f-47b3-9f78-3fb41968a586",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_path = \"face model/\"\n",
    "age_path = \"age model/\"\n",
    "in_image_path = \"images/\"\n",
    "confidence_score = 0.6\n",
    "age_buckets = [\"(0-2)\", \"(4-6)\", \"(8-12)\", \n",
    "               \"(15-20)\", \"(25-32)\",\"(38-43)\", \n",
    "               \"(48-53)\", \"(60-100)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c105b249-9d4a-45e2-9670-6b9de0025888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face model/face.prototxt\n"
     ]
    }
   ],
   "source": [
    "protoFile = os.path.join(face_path, \"face.prototxt\")\n",
    "print(protoFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b176bf08-9fab-4916-9177-d8c222845f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading the model - face detector...\n",
      "\n",
      "[INFO] Loaded the face model...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Loading the model - face detector...\\n\")\n",
    "face_proto_path = os.path.join(face_path, \"face.prototxt\")\n",
    "face_weights_path = os.path.join(face_path, \"res10_300x300_ssd_iter_140000.caffemodel\")\n",
    "\n",
    "# reading the models and loading the weights to the model\n",
    "face_model = cv2.dnn.readNet(face_proto_path, face_weights_path)\n",
    "print(\"[INFO] Loaded the face model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "704b1bae-1c05-4b34-a1e8-517babde7bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading the age detector model..\n",
      "\n",
      "[INFO] Loaded the age model..\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Loading the age detector model..\\n\")\n",
    "age_proto_path = os.path.join(age_path, \"age.prototxt\")\n",
    "age_weights_path = os.path.join(age_path, \"age_net.caffemodel\")\n",
    "\n",
    "# reading the weights and making the model.\n",
    "\n",
    "age_model = cv2.dnn.readNet(age_proto_path, age_weights_path)\n",
    "print(\"[INFO] Loaded the age model..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dc2be78-2a3b-4c96-abea-3517e993ff2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The shape of image is: (707, 567, 3)\n",
      "[INFO] Computing Face detections...\n",
      "[INFO] completed!..\n"
     ]
    }
   ],
   "source": [
    "image = \"shehzen.png\"\n",
    "in_image = cv2.imread(os.path.join(in_image_path, image))\n",
    "\n",
    "(h, w) = in_image.shape[:2]\n",
    "print(f\"[INFO] The shape of image is: {in_image.shape}\")\n",
    "image_blob = cv2.dnn.blobFromImage(in_image, 1.0, \n",
    "                                   (300,300), \n",
    "                                   (104.0, 177.0, 123.0))\n",
    "# blobFromImage(image, scale, resize, mean_subtraction)\n",
    "print(\"[INFO] Computing Face detections...\")\n",
    "face_model.setInput(image_blob)\n",
    "detections = face_model.forward()\n",
    "print(\"[INFO] completed!..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b910e1d6-2910-4ee9-9ca4-bfa98f0560d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.        , 1.        , 0.9996507 , ..., 0.3235973 ,\n",
       "          0.68651354, 0.7475575 ],\n",
       "         [0.        , 1.        , 0.12607715, ..., 0.17958589,\n",
       "          0.5911449 , 0.20981   ],\n",
       "         [0.        , 1.        , 0.11718853, ..., 4.011892  ,\n",
       "          4.8434434 , 4.9840035 ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]]]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections # list of all the detections, which it thinks is a face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0118dba3-07ea-4eb8-82e4-9f57d8574ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 200, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e41ec707-2b49-4ca6-98ba-de8ba9164ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996507"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections[0,0,0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "777cff03-9a95-4fc7-9d13-83b2b414f0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, detections.shape[2]):\n",
    "    confidence = detections[0,0,i, 2] \n",
    "    \n",
    "    if confidence > confidence_score:\n",
    "        box = detections[0,0,i,3:7]*np.array([w,h,w,h])\n",
    "        (x1, y1, x2, y2) = box.astype(\"int\")\n",
    "        face = in_image[y1:y2, x1:x2]\n",
    "        # cv2.imshow(\"image\", face)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "        face_blob = cv2.dnn.blobFromImage(face, 1.0, (227, 227), \n",
    "                                         (78.42, 87.76, 114.89), swapRB=False)\n",
    "        age_model.setInput(face_blob)\n",
    "        preds = age_model.forward()\n",
    "        # print(preds)\n",
    "        i = preds[0].argmax()\n",
    "        age = age_buckets[i]\n",
    "        \n",
    "        age_conf = preds[0][i]\n",
    "        text = \"{}: {:.2f}%\".format(age, age_conf*100)\n",
    "        \n",
    "        y = y1 - 10 if y1 - 10 > 10 else y +10\n",
    "        \n",
    "        cv2.rectangle(in_image, (x1, y1), (x2, y2), (0, 0, 255), 5)\n",
    "        \n",
    "        cv2.putText(in_image, text, (x1, y),cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1, (0,255,255), 2)\n",
    "cv2.imshow(\"Age: \", in_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc4bf9e6-b47f-4a87-a013-ff4fd828a4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.332358  , 0.3235973 , 0.68651354, 0.7475575 ], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections[0,0,0,3:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fc801f-1445-4a40-8317-f781ad4f2bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
